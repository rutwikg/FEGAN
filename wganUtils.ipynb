{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dbe437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d5fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNormalization(tf.keras.layers.Layer):\n",
    "  \"\"\"Instance Normalization Layer (https://arxiv.org/abs/1607.08022).\"\"\"\n",
    "\n",
    "  def __init__(self, epsilon=1e-5):\n",
    "    super(InstanceNormalization, self).__init__()\n",
    "    self.epsilon = epsilon\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.scale = self.add_weight(\n",
    "        name='scale',\n",
    "        shape=input_shape[-1:],\n",
    "        initializer=tf.random_normal_initializer(1., 0.02),\n",
    "        trainable=True)\n",
    "\n",
    "    self.offset = self.add_weight(\n",
    "        name='offset',\n",
    "        shape=input_shape[-1:],\n",
    "        initializer='zeros',\n",
    "        trainable=True)\n",
    "\n",
    "  def call(self, x):\n",
    "    mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "    inv = tf.math.rsqrt(variance + self.epsilon)\n",
    "    normalized = (x - mean) * inv\n",
    "    return self.scale * normalized + self.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b021aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, norm_type='instancenorm',apply_norm=True,  last=False):\n",
    "    #Random Initialization of parameters\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_norm:\n",
    "        if norm_type.lower() == 'batchnorm':\n",
    "            result.add(tf.keras.layers.BatchNormalization())\n",
    "        elif norm_type.lower() == 'instancenorm':\n",
    "            result.add(InstanceNormalization())\n",
    "        result.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    if last:\n",
    "        result.add(tf.keras.layers.Concatenate((1,1,1,512)))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def upsample(filters, size, norm_type='batchnorm', apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if norm_type.lower() == 'batchnorm':\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "    elif norm_type.lower() == 'instancenorm':\n",
    "        result.add(InstanceNormalization())\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ddb8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unetGenerator256():\n",
    "  norm_type = 'instancenorm'\n",
    "  inputs = tf.keras.layers.Input(shape=[256, 256, 6])\n",
    "\n",
    "  down_stack = [\n",
    "      \n",
    "    downsample(256,   4, apply_norm=False),  # (bs, 512, 512, 64)\n",
    "    downsample(512,  4, norm_type),  # (bs, 256, 256, 128)\n",
    "    downsample(512,  4, norm_type),  # (bs, 128, 128, 256\n",
    "    downsample(512,  4, norm_type),  # (bs, 64, 64, 512)\n",
    "    downsample(512,  4, norm_type),  # (bs, 32, 32, 1024)\n",
    "    downsample(512,  4, norm_type),  # (bs, 16, 16, 2048)\n",
    "  \n",
    "  ]\n",
    "\n",
    "  up_stack = [\n",
    "\n",
    "    upsample(512, 4, apply_dropout=True),  # (bs, 4, 4, 1024)\n",
    "    upsample(512, 4, apply_dropout=True),  # (bs, 8, 8, 1024)\n",
    "    upsample(512, 4),  # (bs, 16, 16, 1024)\n",
    "    upsample(512, 4),  # (bs, 32, 32, 512)\n",
    "    upsample(256, 4),  # (bs, 32, 32, 512)\n",
    "    upsample(128, 4),  # (bs, 64, 64, 256)\n",
    "    upsample(64, 4),  # (bs, 128, 128, 128)\n",
    "      \n",
    "  ]\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "  last = tf.keras.layers.Conv2DTranspose(3, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh')  # (bs, 256, 256, 3)\n",
    "\n",
    "  x = inputs\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = []\n",
    "  for down in down_stack:\n",
    "    x = down(x)\n",
    "#     if down==down_stack[-1]:\n",
    "#         x = tf.keras.layers.Concatenate()\n",
    "    skips.append(x)\n",
    "\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    x = tf.keras.layers.Concatenate()([x, skip])\n",
    "#     x = tf.keras.layers.Concatenate()([x, datainp])\n",
    "\n",
    "  x = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d70a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unetGenerator512():\n",
    "  norm_type = 'instancenorm'\n",
    "  inputs = tf.keras.layers.Input(shape=[512, 512, 6])\n",
    "  conds  = tf.keras.layers.Input(shape=[1,1,4])\n",
    "\n",
    "  down_stack = [\n",
    "      \n",
    "    downsample(256,   4, apply_norm=False),  # (bs, 512, 512, 64)\n",
    "    downsample(512,  4, norm_type),  # (bs, 256, 256, 128)\n",
    "    downsample(512,  4, norm_type),  # (bs, 128, 128, 256\n",
    "    downsample(512,  4, norm_type),  # (bs, 64, 64, 512)\n",
    "    downsample(512,  4, norm_type),  # (bs, 32, 32, 1024)\n",
    "    downsample(1024,  4, norm_type),  # (bs, 16, 16, 2048)\n",
    "  \n",
    "  ]\n",
    "\n",
    "  up_stack = [\n",
    "\n",
    "    upsample(512, 4, apply_dropout=True),  # (bs, 4, 4, 1024)\n",
    "    upsample(512, 4, apply_dropout=True),  # (bs, 8, 8, 1024)\n",
    "    upsample(512, 4),  # (bs, 16, 16, 1024)\n",
    "    upsample(512, 4),  # (bs, 32, 32, 512)\n",
    "    upsample(256, 4),  # (bs, 32, 32, 512)\n",
    "    upsample(128, 4),  # (bs, 64, 64, 256)\n",
    "    upsample(64, 4),  # (bs, 128, 128, 128)\n",
    "      \n",
    "  ]\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "  last = tf.keras.layers.Conv2DTranspose(3, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh')  # (bs, 256, 256, 3)\n",
    "\n",
    "  x = inputs\n",
    "  # Downsampling through the model\n",
    "  skips = []\n",
    "  for down in down_stack:\n",
    "    x = down(x)\n",
    "     if down==down_stack[-1]:\n",
    "         x = tf.keras.layers.Concatenate(x,conds)\n",
    "    skips.append(x)\n",
    "\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    if up==up_stack[0]:\n",
    "        x = tf.keras.layers.Concatenate(x,conds)\n",
    "    x = tf.keras.layers.Concatenate()([x, skip])\n",
    "#     x = tf.keras.layers.Concatenate()([x, datainp])\n",
    "\n",
    "  x = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "246ac39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = unetGenerator512()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# with tf.device('/CPU:0'):\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "generator = unetGenerator512()\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)\n",
    "dot_img_file = 'model_1.png'\n",
    "tf.keras.utils.plot_model(generator, to_file=dot_img_file, show_shapes=True,dpi=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a5c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchDiscriminator():\n",
    "    norm_type = 'instancenorm'\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[256, 256, 6], name='input_image')\n",
    "    x = inp\n",
    "\n",
    "    \n",
    "    tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
    "    x = tf.keras.layers.concatenate([inp, tar])  # (bs, 256, 256, channels*2)\n",
    "\n",
    "    down1 = downsample(64,   4, norm_type, False)(x)  # (bs, 128, 128, 64)\n",
    "    down2 = downsample(128,  4, norm_type)(down1)  # (bs, 64, 64, 128)\n",
    "    down3 = downsample(256,  4, norm_type)(down2)  # (bs, 32, 32, 256)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (bs, 34, 34, 256)\n",
    "    \n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1)  # (bs, 31, 31, 512)\n",
    "\n",
    "    if norm_type.lower() == 'batchnorm':\n",
    "        norm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "    elif norm_type.lower() == 'instancenorm':\n",
    "        norm1 = InstanceNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (bs, 33, 33, 512)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e17c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchDiscriminator512():\n",
    "    norm_type = 'instancenorm'\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[512, 512, 6], name='input_image')\n",
    "    x = inp\n",
    "\n",
    "    \n",
    "    tar = tf.keras.layers.Input(shape=[512, 512, 3], name='target_image')\n",
    "    x = tf.keras.layers.concatenate([inp, tar])  # (bs, 256, 256, channels*2)\n",
    "\n",
    "    down1 = downsample(64,   4, norm_type, False)(x)  # (bs, 128, 128, 64)\n",
    "    down2 = downsample(128,  4, norm_type)(down1)  # (bs, 64, 64, 128)\n",
    "    down3 = downsample(256,  4, norm_type)(down2)  # (bs, 32, 32, 256)\n",
    "    down4 = downsample(512,  4, norm_type)(down3)  # (bs, 32, 32, 256)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down4)  # (bs, 34, 34, 256)\n",
    "    \n",
    "    conv = tf.keras.layers.Conv2D(1024, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1)  # (bs, 31, 31, 512)\n",
    "\n",
    "    if norm_type.lower() == 'batchnorm':\n",
    "        norm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "    elif norm_type.lower() == 'instancenorm':\n",
    "        norm1 = InstanceNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (bs, 33, 33, 512)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# with tf.device('/CPU:0'):\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "discriminator = patchDiscriminator512()\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c541997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classicDiscriminator():\n",
    "    norm_type = 'instancenorm'\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "    x = inp\n",
    "    \n",
    "    down1 = downsample(64,   4, norm_type, False)(x)  # (bs, 128, 128, 64)\n",
    "    down2 = downsample(128,  4, norm_type)(down1)  # (bs, 64, 64, 128)\n",
    "    down3 = downsample(256,  4, norm_type)(down2)  # (bs, 32, 32, 256)\n",
    "    down4 = downsample(256,  4, norm_type)(down3)\n",
    "    down5 = downsample(1,    4, norm_type)(down4)\n",
    "    \n",
    "    down6 = tf.keras.layers.Flatten()(down5)\n",
    "    last  = tf.keras.layers.Dense(1)(down6)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inp, outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86453f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classicDiscriminator512():\n",
    "    norm_type = 'instancenorm'\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[512, 512, 3], name='input_image')\n",
    "    x = inp\n",
    "    \n",
    "    down1 = downsample(64,   4, norm_type, False)(x)  # (bs, 128, 128, 64)\n",
    "    down2 = downsample(128,  4, norm_type)(down1)  # (bs, 64, 64, 128)\n",
    "    down3 = downsample(256,  4, norm_type)(down2)  # (bs, 32, 32, 256)\n",
    "    down4 = downsample(512,  4, norm_type)(down3)\n",
    "    down5 = downsample(512,  4, norm_type)(down4)\n",
    "    down6 = downsample(1,    4, norm_type)(down5)\n",
    "    \n",
    "    down7 = tf.keras.layers.Flatten()(down6)\n",
    "    last  = tf.keras.layers.Dense(1)(down7)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inp, outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e61122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classicGenerator():\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874827ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
